{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552332ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_vggt = \"cpu\"\n",
    "# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \n",
    "dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e174d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGT(\n",
       "  (aggregator): Aggregator(\n",
       "    (patch_embed): DinoVisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-23): 24 x NestedTensorBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MemEffAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (rope): RotaryPositionEmbedding2D()\n",
       "    (frame_blocks): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (rope): RotaryPositionEmbedding2D()\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (global_blocks): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (k_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (rope): RotaryPositionEmbedding2D()\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (camera_head): CameraHead(\n",
       "    (trunk): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (token_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (trunk_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (embed_pose): Linear(in_features=9, out_features=2048, bias=True)\n",
       "    (poseLN_modulation): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "    )\n",
       "    (adaln_norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=False)\n",
       "    (pose_branch): Mlp(\n",
       "      (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=1024, out_features=9, bias=True)\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (point_head): DPTHead(\n",
       "    (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (projects): ModuleList(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2-3): 2 x Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (resize_layers): ModuleList(\n",
       "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (2): Identity()\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (scratch): Module(\n",
       "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (refinenet1): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet2): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet3): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet4): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (output_conv2): Sequential(\n",
       "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (depth_head): DPTHead(\n",
       "    (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    (projects): ModuleList(\n",
       "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2-3): 2 x Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (resize_layers): ModuleList(\n",
       "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (2): Identity()\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (scratch): Module(\n",
       "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (refinenet1): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet2): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet3): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit1): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (refinenet4): FeatureFusionBlock(\n",
       "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (resConfUnit2): ResidualConvUnit(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (output_conv2): Sequential(\n",
       "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (track_head): TrackHead(\n",
       "    (feature_extractor): DPTHead(\n",
       "      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (projects): ModuleList(\n",
       "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2-3): 2 x Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (resize_layers): ModuleList(\n",
       "        (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): Identity()\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (scratch): Module(\n",
       "        (layer1_rn): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer2_rn): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer3_rn): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (layer4_rn): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (refinenet1): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet2): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet3): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit1): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (refinenet4): FeatureFusionBlock(\n",
       "          (out_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (resConfUnit2): ResidualConvUnit(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (activation): ReLU(inplace=True)\n",
       "            (skip_add): FloatFunctional(\n",
       "              (activation_post_process): Identity()\n",
       "            )\n",
       "          )\n",
       "          (skip_add): FloatFunctional(\n",
       "            (activation_post_process): Identity()\n",
       "          )\n",
       "        )\n",
       "        (output_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (tracker): BaseTrackerPredictor(\n",
       "      (corr_mlp): Mlp(\n",
       "        (fc1): Linear(in_features=567, out_features=384, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=384, out_features=128, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (updateformer): EfficientUpdateFormer(\n",
       "        (input_norm): LayerNorm((388,), eps=1e-05, elementwise_affine=True)\n",
       "        (input_transform): Linear(in_features=388, out_features=384, bias=True)\n",
       "        (output_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (flow_head): Linear(in_features=384, out_features=130, bias=True)\n",
       "        (time_blocks): ModuleList(\n",
       "          (0-5): 6 x AttnBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (space_virtual_blocks): ModuleList(\n",
       "          (0-5): 6 x AttnBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (space_point2virtual_blocks): ModuleList(\n",
       "          (0-5): 6 x CrossAttnBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm_context): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (space_virtual2point_blocks): ModuleList(\n",
       "          (0-5): 6 x CrossAttnBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm_context): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0, inplace=False)\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fmap_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffeat_norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (ffeat_updater): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (vis_predictor): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "      (conf_predictor): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model and load the pretrained weights.\n",
    "# This will automatically download the model weights the first time it's run, which may take a while.\n",
    "model_vggt = VGGT()\n",
    "_URL = \"https://huggingface.co/facebook/VGGT-1B/resolve/main/model.pt\"\n",
    "model_vggt.load_state_dict(torch.hub.load_state_dict_from_url(_URL))\n",
    "model_vggt.to(device_vggt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0cb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE=\"bicycle\"\n",
    "SKIP=25\n",
    "\n",
    "if SCENE==\"banana\": \n",
    "    # Load and preprocess example images (replace with your own image paths)\n",
    "    image_names = [\n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00001.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00002.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00003.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00004.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00005.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00006.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00007.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00008.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00009.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00010.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00011.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00012.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00013.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00014.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00015.JPG\", \n",
    "        \"/home/skhalid/Documents/data/banana/input/frame_00016.JPG\"\n",
    "    ]\n",
    "    ### BANANA\n",
    "    width = 3008\n",
    "    height = 2000\n",
    "    BASE_PATH = \"/home/skhalid/Documents/data/banana\"\n",
    "    INTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/cameras.bin\"\n",
    "    EXTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/images.bin\"\n",
    "    PTS_PATH = BASE_PATH+\"/sparse/0/points3D.ply\"\n",
    "    PREFIX = \"frame_\"\n",
    "    START_ID = 0\n",
    "    N = 200_000\n",
    "\n",
    "elif SCENE==\"lego\": \n",
    "    ### LEGO\n",
    "    image_names = [\"/home/skhalid/Documents/data/nerf_synthetic/lego/train/r_\"+str(v)+\".png\" for v in range(0, 99, SKIP)]\n",
    "    width = 800\n",
    "    height = 800\n",
    "    BASE_PATH = \"/home/skhalid/Documents/data/nerf_synthetic/lego/\"\n",
    "    INTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/cameras.bin\"\n",
    "    EXTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/images.bin\"\n",
    "    PTS_PATH = BASE_PATH+\"/sparse/0/points3D.ply\"\n",
    "    PREFIX = \"r_\"\n",
    "    START_ID = 0\n",
    "    N = 200_000\n",
    "\n",
    "elif SCENE==\"bicycle\": \n",
    "    ### BICYCLE\n",
    "    BASE=\"/home/skhalid/Documents/data/360_v2/bicycle/images_4/_DSC\"\n",
    "    image_names = [BASE+str(v)+\".JPG\" for v in range(8679, 8873, SKIP)]\n",
    "    width = 1236\n",
    "    height = 821    \n",
    "    BASE_PATH = \"/home/skhalid/Documents/data/360_v2/bicycle\"\n",
    "    INTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/cameras.bin\"\n",
    "    EXTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/images.bin\"\n",
    "    PTS_PATH = BASE_PATH+\"/sparse/0/points3D.ply\"\n",
    "    PREFIX = \"_DSC\"\n",
    "    START_ID = 0\n",
    "    N = 1_000_000\n",
    "    # test_cases = [\"8679.JPG\",\n",
    "    #               \"8687.JPG\",\n",
    "    #               \"8695.JPG\",\n",
    "    #               \"8703.JPG\",\n",
    "    #               \"8711.JPG\",\n",
    "    #               \"8719.JPG\",\n",
    "    #               \"8727.JPG\",\n",
    "    #               \"8735.JPG\",\n",
    "    #               \"8744.JPG\",\n",
    "    #               \"8752.JPG\",\n",
    "    #               \"8760.JPG\",\n",
    "    #               \"8768.JPG\",\n",
    "    #               \"8776.JPG\",\n",
    "    #               \"8784.JPG\",\n",
    "    #               \"8792.JPG\",\n",
    "    #               \"8800.JPG\",\n",
    "    #               \"8808.JPG\",\n",
    "    #               \"8816.JPG\",\n",
    "    #               \"8824.JPG\",\n",
    "    #               \"8832.JPG\",\n",
    "    #               \"8840.JPG\",\n",
    "    #               \"8848.JPG\",\n",
    "    #               \"8856.JPG\",\n",
    "    #               \"8864.JPG\",\n",
    "    #               \"8872.JPG\"]\n",
    "    # for test_case in test_cases:\n",
    "    #     image_names.append(BASE+str(test_case))\n",
    "\n",
    "elif SCENE==\"truck\": \n",
    "    ### BICYCLE\n",
    "    BASE=\"/home/skhalid/Documents/data/tandt_db/tandt/truck/images/\"\n",
    "    image_names = [BASE+str(v).zfill(6)+\".jpg\" for v in range(1, 252, SKIP)]\n",
    "    width = 1957\n",
    "    height = 1091    \n",
    "    BASE_PATH = \"/home/skhalid/Documents/data/tandt_db/tandt/truck\"\n",
    "    INTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/cameras.bin\"\n",
    "    EXTRINSICS_BINARY_PATH = BASE_PATH+\"/sparse/0/images.bin\"\n",
    "    PTS_PATH = BASE_PATH+\"/sparse/0/points3D.ply\"\n",
    "    PREFIX = \"\"\n",
    "    START_ID = 0\n",
    "    N = 1_000_000\n",
    "    # test_cases = [\"8679.JPG\",\n",
    "    #               \"8687.JPG\",\n",
    "    #               \"8695.JPG\",\n",
    "    #               \"8703.JPG\",\n",
    "    #               \"8711.JPG\",\n",
    "    #               \"8719.JPG\",\n",
    "    #               \"8727.JPG\",\n",
    "    #               \"8735.JPG\",\n",
    "    #               \"8744.JPG\",\n",
    "    #               \"8752.JPG\",\n",
    "    #               \"8760.JPG\",\n",
    "    #               \"8768.JPG\",\n",
    "    #               \"8776.JPG\",\n",
    "    #               \"8784.JPG\",\n",
    "    #               \"8792.JPG\",\n",
    "    #               \"8800.JPG\",\n",
    "    #               \"8808.JPG\",\n",
    "    #               \"8816.JPG\",\n",
    "    #               \"8824.JPG\",\n",
    "    #               \"8832.JPG\",\n",
    "    #               \"8840.JPG\",\n",
    "    #               \"8848.JPG\",\n",
    "    #               \"8856.JPG\",\n",
    "    #               \"8864.JPG\",\n",
    "    #               \"8872.JPG\"]\n",
    "    # for test_case in test_cases:\n",
    "    #     image_names.append(BASE+str(test_case))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e13e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b124f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_batched_camera_inference(model, image_names, batch_size=8, device='cuda', dtype=torch.float16):\n",
    "    from vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "    from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "    # from vggt.utils.io import load_and_preprocess_images\n",
    "\n",
    "    all_extrinsics = []\n",
    "    all_intrinsics = []\n",
    "    all_world_points = []\n",
    "    depth_maps = []\n",
    "    depth_conf_maps = []\n",
    "    batch_tensors = []\n",
    "    agg_tokens_tensor = torch.Tensor([]).to(device)\n",
    "    ps_idx_list = []\n",
    "\n",
    "    # Batch the rest of the images\n",
    "    print(f\"Processing the rest of {len(image_names)} images in batches of {batch_size}...\")\n",
    "    for i in tqdm(range(0, len(image_names), batch_size)):\n",
    "        batch_names = image_names[i:i + batch_size]\n",
    "        batch_tensor = load_and_preprocess_images(batch_names).to(device)\n",
    "\n",
    "        if i==0:\n",
    "            first_image = batch_tensor[0]\n",
    "            print(\"first_image.shape: {}\".format(batch_tensor.shape))\n",
    "        else:\n",
    "            # Add the first reference image to this batch as well\n",
    "            batch_tensor = torch.cat((first_image[None], batch_tensor), dim=0)\n",
    "\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast(dtype=dtype):\n",
    "            batch_tensor = batch_tensor[None]  # Add batch dim\n",
    "            agg_tokens, ps_idx = model.aggregator(batch_tensor)\n",
    "\n",
    "            pose_enc = model.camera_head(agg_tokens)[-1]\n",
    "            extrinsic, intrinsic = pose_encoding_to_extri_intri(pose_enc, batch_tensor.shape[-2:])\n",
    "\n",
    "            depth_map, depth_conf_map = model.depth_head(agg_tokens, batch_tensor, ps_idx)\n",
    "            \n",
    "            point_map_unproj = unproject_depth_map_to_point_map(depth_map.squeeze(0), extrinsic.squeeze(0), intrinsic.squeeze(0))\n",
    "    \n",
    "            # if i==0:    \n",
    "            #     print(\"batch: {} | point_map_unproj.shape: {}\".format(i, point_map_unproj.shape))\n",
    "            # else:\n",
    "            #     print(\"batch: {} | point_map_unproj[1:, ...].shape: {}\".format(i, point_map_unproj[1:, ...].shape))\n",
    "\n",
    "            # ==== USAGE ====\n",
    "            # Inputs\n",
    "            # mask: binary torch.Tensor of shape (H, W)\n",
    "            # images: list of images (B, C, H, W) â€” assume 1 scene for simplicity\n",
    "            agg_tokens = torch.stack(agg_tokens)\n",
    "\n",
    "            if i==0:\n",
    "                all_extrinsics.append(extrinsic[0, ...])\n",
    "                all_intrinsics.append(intrinsic[0, ...])\n",
    "                all_world_points.append(point_map_unproj)\n",
    "                depth_maps.append(depth_map[0, ...])\n",
    "                depth_conf_maps.append(depth_conf_map[0, ...])\n",
    "                batch_tensors.append(batch_tensor[0, ...])\n",
    "                agg_tokens_tensor = torch.cat((agg_tokens_tensor, agg_tokens), dim=0)\n",
    "                ps_idx_list.append(ps_idx)\n",
    "            else:\n",
    "                all_extrinsics.append(extrinsic[0, 1:])\n",
    "                all_intrinsics.append(intrinsic[0, 1:])\n",
    "                all_world_points.append(point_map_unproj[1:, ...])\n",
    "                depth_maps.append(depth_map[0, 1:, ...])\n",
    "                depth_conf_maps.append(depth_conf_map[0, 1:, ...])\n",
    "                batch_tensors.append(batch_tensor[0, 1:, ...])\n",
    "                agg_tokens_tensor = torch.cat((agg_tokens_tensor, agg_tokens), dim=0)\n",
    "                ps_idx_list.append(ps_idx)\n",
    "\n",
    "            # print(\"extrinsic: {}\".format(extrinsic.shape))\n",
    "            # print(\"intrinsic: {}\".format(intrinsic.shape))\n",
    "            # print(\"point_map_unproj: {}\".format(point_map_unproj.shape))\n",
    "            # print(\"depth_map: {}\".format(depth_map.shape))\n",
    "            # print(\"depth_conf_map: {}\".format(depth_conf_map.shape))\n",
    "            # print(\"batch_tensor: {}\".format(batch_tensor.shape))\n",
    "\n",
    "    # Stack everything\n",
    "    batch_tensors = torch.cat(batch_tensors)  # [N, 4, 4]\n",
    "    all_extrinsics = torch.cat(all_extrinsics)  # [N, 4, 4]\n",
    "    all_intrinsics = torch.cat(all_intrinsics)  # [N, 3, 3]\n",
    "    all_world_points = np.concatenate(all_world_points)  # [N, H, W, 3]\n",
    "    depth_maps = torch.cat(depth_maps, dim=0)  # [N, H, W, 3]\n",
    "    depth_conf_maps = torch.cat(depth_conf_maps, dim=0)  # [N, H, W, 3]\n",
    "    # aggregated_tokens_list = torch.cat(aggregated_tokens_list, dim=0)  # [N, H, W, 3]\n",
    "    # ps_idx_list = torch.cat(ps_idx_list, dim=0)  # [N, H, W, 3]\n",
    "\n",
    "    return {\n",
    "        \"all_extrinsics\": all_extrinsics, \n",
    "        \"all_intrinsics\": all_intrinsics, \n",
    "        \"all_world_points\": all_world_points,\n",
    "        \"depth_maps\": depth_maps,\n",
    "        \"depth_conf_maps\": depth_conf_maps,\n",
    "        \"all_images\": batch_tensors,\n",
    "        \"aggregated_tokens_list\": agg_tokens_tensor,\n",
    "        \"ps_idx_list\": ps_idx_list\n",
    "    }\n",
    "\n",
    "    # # Predict Tracks\n",
    "    # # choose your own points to track, with shape (N, 2) for one scene\n",
    "    # query_points = torch.FloatTensor([[100.0, 200.0], \n",
    "    #                                     [60.72, 259.94]]).to(device)\n",
    "    # track_list, vis_score, conf_score = model.track_head(aggregated_tokens_list, images, ps_idx, query_points=query_points[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a370999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the rest of 8 images in batches of 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_image.shape: torch.Size([8, 3, 350, 518])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93448/1998803155.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.1259,  0.1244, -0.2035,  ..., -0.0134,  0.0438,  0.2083],\n",
      "          [ 0.3009,  0.1051, -0.2932,  ..., -0.0378, -0.0317,  0.1899],\n",
      "          [ 0.2893,  0.1372, -0.2837,  ..., -0.0229, -0.0321,  0.1597],\n",
      "          ...,\n",
      "          [ 0.1599,  0.0303,  0.0073,  ...,  0.0337,  0.0842,  0.0848],\n",
      "          [ 0.2834,  0.2385, -0.0604,  ...,  0.0200,  0.0172,  0.1497],\n",
      "          [ 0.1142,  0.0102, -0.0569,  ...,  0.0737,  0.0645,  0.1010]],\n",
      "\n",
      "         [[ 0.0818,  0.1083, -0.0269,  ...,  0.1343,  0.0527,  0.0195],\n",
      "          [ 0.0761,  0.0978, -0.0468,  ...,  0.1558,  0.0557,  0.0360],\n",
      "          [ 0.0828,  0.0317, -0.0435,  ...,  0.0844, -0.0303,  0.0932],\n",
      "          ...,\n",
      "          [ 0.0958, -0.0318, -0.0786,  ...,  0.1201, -0.0674,  0.0840],\n",
      "          [-0.0763,  0.1382,  0.0206,  ...,  0.2143,  0.1689,  0.0726],\n",
      "          [ 0.0262, -0.0609, -0.1491,  ...,  0.1326,  0.0061,  0.1204]],\n",
      "\n",
      "         [[ 0.2076,  0.0749, -0.1057,  ..., -0.0732,  0.0327,  0.1807],\n",
      "          [ 0.3364, -0.0596, -0.1243,  ..., -0.0531,  0.0387,  0.1011],\n",
      "          [ 0.2770,  0.1218,  0.0712,  ..., -0.0390,  0.0125,  0.1125],\n",
      "          ...,\n",
      "          [ 0.2319, -0.1149, -0.0144,  ..., -0.0088, -0.0334,  0.0495],\n",
      "          [ 0.1255,  0.0297,  0.0083,  ...,  0.0063,  0.0478,  0.1209],\n",
      "          [ 0.0945,  0.0625, -0.0750,  ...,  0.0100,  0.0709,  0.0800]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1450,  0.0970, -0.1135,  ...,  0.0279,  0.0338,  0.1403],\n",
      "          [ 0.1620,  0.0315, -0.1629,  ...,  0.0741,  0.0169,  0.0649],\n",
      "          [ 0.2571, -0.1139,  0.0918,  ...,  0.0427,  0.0140,  0.0592],\n",
      "          ...,\n",
      "          [ 0.1663,  0.1331,  0.1164,  ...,  0.0446,  0.0016,  0.2689],\n",
      "          [ 0.1032,  0.1948, -0.0228,  ...,  0.1142, -0.0149,  0.2082],\n",
      "          [ 0.1236,  0.1456, -0.0925,  ...,  0.1066, -0.0503,  0.1899]],\n",
      "\n",
      "         [[ 0.2550, -0.1263, -0.1518,  ...,  0.1246,  0.0031,  0.0264],\n",
      "          [ 0.0968,  0.1113, -0.2355,  ...,  0.1137,  0.0074,  0.1025],\n",
      "          [ 0.1536, -0.0606, -0.1690,  ...,  0.0725,  0.0723,  0.1440],\n",
      "          ...,\n",
      "          [ 0.2233, -0.0182, -0.1568,  ...,  0.0719,  0.0537,  0.0240],\n",
      "          [ 0.2639, -0.0920, -0.1157,  ...,  0.0761, -0.0632, -0.0667],\n",
      "          [ 0.2232,  0.0087, -0.1327,  ...,  0.1241,  0.0646,  0.0340]],\n",
      "\n",
      "         [[ 0.1932,  0.0391, -0.0936,  ..., -0.0320,  0.0789,  0.0782],\n",
      "          [ 0.2499,  0.1410, -0.0555,  ...,  0.0211,  0.0140,  0.0993],\n",
      "          [ 0.1622,  0.1738, -0.0462,  ...,  0.0468, -0.0236,  0.1744],\n",
      "          ...,\n",
      "          [ 0.3147,  0.1327, -0.0672,  ..., -0.0572,  0.0145,  0.0536],\n",
      "          [ 0.2332,  0.1650, -0.1004,  ..., -0.0214,  0.0635,  0.0978],\n",
      "          [ 0.1710,  0.1872, -0.0977,  ...,  0.0375,  0.0471,  0.1037]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.0878,  0.3312, -0.2650,  ..., -0.1087, -0.1744,  0.3490],\n",
      "          [-0.0919,  0.2548, -0.4054,  ..., -0.0286, -0.0843,  0.3461],\n",
      "          [-0.1330,  0.3275, -0.3135,  ...,  0.1337, -0.0743,  0.2687],\n",
      "          ...,\n",
      "          [-0.0015,  0.2584,  0.0418,  ..., -0.0725, -0.0303,  0.1528],\n",
      "          [ 0.1531,  0.5510,  0.0249,  ..., -0.0077, -0.1025,  0.1117],\n",
      "          [ 0.0277,  0.2068, -0.0364,  ..., -0.1050, -0.2995,  0.1406]],\n",
      "\n",
      "         [[ 0.1051,  0.2430, -0.0926,  ..., -0.1076, -0.1767,  0.2388],\n",
      "          [ 0.0607,  0.2085, -0.1344,  ..., -0.0591, -0.1002,  0.2945],\n",
      "          [ 0.0189,  0.1102, -0.1465,  ..., -0.1299, -0.2520,  0.3511],\n",
      "          ...,\n",
      "          [ 0.0049,  0.1345, -0.1008,  ...,  0.1276,  0.0807,  0.0099],\n",
      "          [-0.0586,  0.3125,  0.0596,  ...,  0.0311,  0.1227, -0.1290],\n",
      "          [-0.0068,  0.1767, -0.1635,  ...,  0.0560,  0.0816, -0.0361]],\n",
      "\n",
      "         [[ 0.1285,  0.2902, -0.2148,  ..., -0.1607, -0.1963,  0.3779],\n",
      "          [ 0.1067,  0.1775, -0.1622,  ..., -0.2355, -0.0716,  0.2989],\n",
      "          [-0.0143,  0.2545, -0.0216,  ..., -0.0793,  0.0523,  0.3806],\n",
      "          ...,\n",
      "          [ 0.1304,  0.0811, -0.1263,  ...,  0.0952, -0.2146,  0.0240],\n",
      "          [ 0.0576,  0.2109, -0.0577,  ..., -0.0439, -0.1679,  0.1089],\n",
      "          [ 0.0326,  0.2778, -0.0988,  ..., -0.1138, -0.1959,  0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1392,  0.1526, -0.1209,  ..., -0.1810, -0.2989,  0.3732],\n",
      "          [ 0.1056,  0.1862,  0.0260,  ..., -0.0427, -0.0709,  0.2445],\n",
      "          [-0.0516, -0.0040,  0.2156,  ...,  0.0447, -0.0911,  0.1404],\n",
      "          ...,\n",
      "          [ 0.2279,  0.3432,  0.0177,  ..., -0.0229, -0.1340,  0.2369],\n",
      "          [ 0.0413,  0.3938,  0.0443,  ...,  0.0084, -0.2503,  0.1736],\n",
      "          [ 0.0700,  0.3162, -0.0086,  ..., -0.0356, -0.3413,  0.0982]],\n",
      "\n",
      "         [[ 0.2162,  0.1556, -0.1287,  ..., -0.0910, -0.1405,  0.2622],\n",
      "          [ 0.1364,  0.3450, -0.2537,  ..., -0.2769, -0.1720,  0.1748],\n",
      "          [-0.1335,  0.2207, -0.0786,  ..., -0.0096, -0.0086,  0.1030],\n",
      "          ...,\n",
      "          [ 0.0709,  0.2678, -0.1341,  ...,  0.1312, -0.0802, -0.0197],\n",
      "          [ 0.1789,  0.2333, -0.0293,  ...,  0.1199, -0.1258, -0.0251],\n",
      "          [ 0.2813,  0.2316, -0.0966,  ..., -0.0011, -0.1379,  0.1974]],\n",
      "\n",
      "         [[ 0.1252,  0.1957, -0.0307,  ..., -0.1480, -0.0046,  0.0955],\n",
      "          [ 0.1696,  0.3108,  0.1178,  ..., -0.0008,  0.0090,  0.0096],\n",
      "          [ 0.0313,  0.3355,  0.0737,  ..., -0.0329, -0.0981,  0.1659],\n",
      "          ...,\n",
      "          [ 0.2073,  0.3531, -0.1202,  ...,  0.0024, -0.1371,  0.1521],\n",
      "          [ 0.0322,  0.3469, -0.1287,  ..., -0.1899, -0.2337,  0.1656],\n",
      "          [-0.0525,  0.3704, -0.0961,  ..., -0.1930, -0.2818,  0.1392]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[-6.3426e-02,  8.4360e-01,  1.1845e-01,  ..., -4.5075e-01,\n",
      "           -8.4719e-01,  7.8349e-03],\n",
      "          [ 1.1558e-01,  2.2285e+00,  1.5191e+00,  ...,  2.4789e-01,\n",
      "            6.5450e-02,  1.5790e-01],\n",
      "          [-2.2372e-02,  2.3674e+00,  1.7386e+00,  ...,  6.1587e-01,\n",
      "            1.7495e-01, -6.0604e-02],\n",
      "          ...,\n",
      "          [-3.2134e-01, -2.2818e+00, -1.6190e+00,  ..., -2.3106e-01,\n",
      "           -9.7322e-02,  1.0244e-01],\n",
      "          [-3.5353e-01, -2.5650e+00, -1.8983e+00,  ...,  8.1255e-03,\n",
      "           -4.9795e-01, -2.1701e-01],\n",
      "          [-1.6986e-01, -2.2721e+00, -1.8264e+00,  ..., -2.2947e-01,\n",
      "           -2.1704e-01,  8.9574e-04]],\n",
      "\n",
      "         [[ 1.4850e-01, -4.4606e-01, -1.0414e-01,  ..., -1.1914e+00,\n",
      "            1.0921e-01,  4.4544e-01],\n",
      "          [ 2.0058e-01, -3.9881e-01, -2.6987e-01,  ..., -9.1076e-01,\n",
      "           -7.0411e-02,  4.6090e-01],\n",
      "          [ 4.1798e-01, -5.1348e-01, -3.3801e-01,  ..., -8.8622e-01,\n",
      "           -2.4506e-01,  6.2107e-01],\n",
      "          ...,\n",
      "          [ 6.3552e-01,  7.2082e-02,  6.9524e-01,  ...,  2.9504e-01,\n",
      "            4.2038e-01,  3.2659e-01],\n",
      "          [-4.5095e-01,  2.3878e-01,  2.5774e-01,  ..., -1.5764e+00,\n",
      "           -5.5915e-01,  5.0730e-01],\n",
      "          [ 1.5453e-01,  4.2570e-01,  8.2350e-01,  ..., -2.6012e-01,\n",
      "           -4.6742e-02, -3.1898e-01]],\n",
      "\n",
      "         [[-2.1398e-01,  1.3455e+00,  4.4880e-01,  ..., -4.9099e-01,\n",
      "           -1.2352e+00,  1.7777e-01],\n",
      "          [-2.1712e-01,  2.8042e+00,  2.2143e+00,  ...,  1.9057e-01,\n",
      "           -8.4446e-02, -2.8494e-01],\n",
      "          [-2.2612e-01,  2.5240e+00,  2.1335e+00,  ...,  1.5292e-01,\n",
      "           -8.0562e-01, -2.3582e-02],\n",
      "          ...,\n",
      "          [-3.9165e-01, -3.4163e+00, -2.0014e+00,  ...,  3.1497e-01,\n",
      "            1.4631e-01,  2.5350e-01],\n",
      "          [-3.9984e-01, -2.4066e+00, -1.4841e+00,  ...,  3.0232e-01,\n",
      "           -2.2027e-01,  9.8912e-02],\n",
      "          [-3.3492e-01, -2.2657e+00, -1.5839e+00,  ...,  2.2141e-01,\n",
      "           -1.3260e-01, -1.3537e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3578e-01, -3.6175e-01, -1.1382e+00,  ..., -4.3260e-01,\n",
      "           -2.7836e-01, -1.3788e+00],\n",
      "          [-3.2437e-02, -9.0201e-01, -3.7615e-01,  ...,  2.7038e-01,\n",
      "            2.0226e-01, -1.5657e+00],\n",
      "          [-1.5897e-01, -8.3690e-01, -4.3084e-02,  ...,  1.8092e-01,\n",
      "           -3.2960e-01, -1.7707e+00],\n",
      "          ...,\n",
      "          [-4.0106e-01,  1.3458e-01,  3.0495e-01,  ..., -1.3673e-01,\n",
      "           -1.8887e-02,  4.9719e-01],\n",
      "          [-4.8726e-01,  5.6146e-01,  4.4952e-01,  ..., -5.2550e-01,\n",
      "            4.9477e-02,  5.8740e-01],\n",
      "          [-3.5562e-01,  3.4837e-01,  2.4703e-01,  ..., -3.7561e-01,\n",
      "            5.6402e-02,  3.4470e-01]],\n",
      "\n",
      "         [[ 5.5898e-01,  1.7398e+00,  1.1800e+00,  ..., -2.1051e-01,\n",
      "            1.1297e-01, -7.5216e-02],\n",
      "          [ 2.0482e-01,  1.1672e+00,  3.4564e-01,  ..., -9.7540e-01,\n",
      "           -5.5565e-01,  5.0574e-02],\n",
      "          [ 5.6860e-01,  1.2874e+00,  7.6318e-01,  ..., -5.3865e-01,\n",
      "            8.0295e-01, -6.3849e-01],\n",
      "          ...,\n",
      "          [ 3.2742e-01, -8.6914e-01, -1.2526e+00,  ...,  4.3121e-01,\n",
      "           -5.2109e-02,  1.7202e-01],\n",
      "          [ 3.5487e-01, -9.2938e-01, -1.1538e+00,  ...,  8.6431e-01,\n",
      "           -2.8313e-01,  1.6582e-01],\n",
      "          [-4.0415e-02, -6.1132e-01, -7.1040e-01,  ..., -2.2949e-01,\n",
      "           -8.9512e-01,  1.2898e+00]],\n",
      "\n",
      "         [[-1.0039e-01,  8.4833e-01,  1.1326e+00,  ..., -6.9183e-01,\n",
      "           -3.3186e-01, -5.8579e-01],\n",
      "          [ 2.8341e-01,  9.4996e-01,  1.9369e+00,  ..., -2.8273e-01,\n",
      "           -5.9238e-01, -3.4072e-01],\n",
      "          [-4.6759e-02,  1.0151e+00,  1.6934e+00,  ..., -4.7245e-01,\n",
      "           -3.9428e-01, -3.4652e-01],\n",
      "          ...,\n",
      "          [-4.5663e-02, -7.2694e-01, -8.2001e-01,  ...,  3.3429e-02,\n",
      "           -1.3399e-01,  4.1352e-01],\n",
      "          [-1.8884e-01, -4.7476e-01, -7.2483e-01,  ..., -2.1267e-01,\n",
      "           -2.9781e-01,  3.6740e-01],\n",
      "          [-2.4155e-01, -3.3377e-01, -7.0971e-01,  ..., -1.8607e-01,\n",
      "           -1.5841e-01,  4.6638e-01]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.5232,  1.8714,  0.6139,  ..., -0.9429, -0.4894, -1.8274],\n",
      "          [ 0.5065,  3.2477,  1.8844,  ..., -0.2371,  0.7376, -1.2827],\n",
      "          [ 0.2628,  3.2643,  2.0421,  ...,  0.0189,  0.7003, -1.5214],\n",
      "          ...,\n",
      "          [ 0.9873, -1.2106, -1.1618,  ..., -1.1084, -0.4767, -1.4066],\n",
      "          [ 1.0382, -1.3374, -1.3391,  ..., -0.7572, -0.7344, -1.6366],\n",
      "          [ 0.9739, -1.1850, -1.3168,  ..., -1.3519, -0.6849, -1.4300]],\n",
      "\n",
      "         [[ 0.1162,  0.5203, -0.3753,  ..., -0.8258, -0.3319, -0.9591],\n",
      "          [ 0.2498,  0.8097, -0.3927,  ..., -0.8184, -0.2067, -0.5229],\n",
      "          [ 0.7625,  0.8739, -0.3081,  ..., -0.8279, -0.0208, -0.0623],\n",
      "          ...,\n",
      "          [-0.7101,  0.6277,  0.6378,  ...,  3.0174, -0.5870, -1.7756],\n",
      "          [-1.5860,  1.2154,  0.5232,  ..., -1.5507, -1.5650, -0.5703],\n",
      "          [-0.9921,  0.8778,  0.5800,  ...,  1.7725, -1.1596, -2.1043]],\n",
      "\n",
      "         [[ 0.1596,  2.6547,  1.2224,  ..., -0.9643, -0.9944, -2.2089],\n",
      "          [ 0.2731,  4.0870,  2.9734,  ..., -0.3678,  0.3037, -2.1805],\n",
      "          [ 0.3998,  3.8678,  2.8707,  ..., -0.7738, -0.3230, -1.8470],\n",
      "          ...,\n",
      "          [ 0.8027, -2.2164, -1.2151,  ..., -0.1487,  0.3572, -1.5569],\n",
      "          [ 0.8564, -1.3605, -0.8704,  ..., -0.1011, -0.1107, -1.8934],\n",
      "          [ 0.9415, -1.2276, -0.9654,  ..., -0.2569, -0.0766, -2.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1380,  0.5446, -2.3084,  ...,  1.0443,  1.4545, -1.4422],\n",
      "          [ 1.7617,  0.2774, -2.0629,  ...,  2.4393,  1.4417, -1.3818],\n",
      "          [ 0.9333,  0.0633, -1.7679,  ...,  1.8153,  0.9755, -1.7045],\n",
      "          ...,\n",
      "          [-0.1882,  1.2956,  1.4099,  ..., -1.5766,  0.3552, -1.2453],\n",
      "          [ 0.2381,  1.6820,  1.3678,  ..., -1.9405,  0.4275, -0.8345],\n",
      "          [ 0.1695,  1.4916,  1.1326,  ..., -1.7996,  0.3520, -1.0046]],\n",
      "\n",
      "         [[ 1.8072,  2.6519,  1.6035,  ..., -1.3032,  0.2511, -1.2411],\n",
      "          [ 1.2261,  2.2579,  1.0852,  ..., -1.9754,  0.0372, -1.6677],\n",
      "          [ 2.0124,  2.2015,  1.3193,  ..., -2.1504,  1.2138, -2.0270],\n",
      "          ...,\n",
      "          [ 0.8061, -0.0548, -1.0241,  ..., -0.6240,  0.0978, -0.6364],\n",
      "          [ 1.0507, -0.1367, -1.0012,  ..., -0.2262, -0.1926, -0.6764],\n",
      "          [ 0.2597,  0.1243, -0.8417,  ..., -0.2500, -0.1504, -0.1217]],\n",
      "\n",
      "         [[ 0.4419,  1.9253,  1.2544,  ...,  1.0133,  0.6522, -1.5997],\n",
      "          [ 0.4475,  1.8666,  1.9161,  ...,  0.9820,  0.5765, -1.4563],\n",
      "          [ 0.1171,  2.3347,  1.9583,  ...,  0.6564,  0.9339, -1.5113],\n",
      "          ...,\n",
      "          [ 1.1442,  0.4232, -0.0798,  ..., -0.5633,  0.1070, -1.1975],\n",
      "          [ 1.1158,  0.6253, -0.0551,  ..., -0.9206, -0.2869, -1.2353],\n",
      "          [ 1.2383,  0.7389, -0.0756,  ..., -0.8615, -0.2700, -1.0975]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.42s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=10\n",
    "\n",
    "predictions = run_batched_camera_inference(model_vggt, image_names, device=device_vggt, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7117a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 4) (8, 3, 3) (8, 350, 518, 3) (8, 350, 518, 1) (8, 350, 518) (8, 3, 350, 518) torch.Size([24, 1, 8, 930, 2048])\n"
     ]
    }
   ],
   "source": [
    "all_extrinsics = predictions[\"all_extrinsics\"].cpu().numpy()\n",
    "all_intrinsics = predictions[\"all_intrinsics\"].cpu().numpy()\n",
    "all_world_points = predictions[\"all_world_points\"]\n",
    "depth_maps = predictions[\"depth_maps\"].cpu().numpy()\n",
    "depth_conf_maps = predictions[\"depth_conf_maps\"].cpu().numpy()\n",
    "all_images = predictions[\"all_images\"].cpu().numpy()\n",
    "ps_idx_list = predictions[\"ps_idx_list\"]\n",
    "aggregated_tokens_tensor = predictions[\"aggregated_tokens_list\"]\n",
    "# ps_idx_list = predictions[\"ps_idx_list\"].cpu().numpy()\n",
    "\n",
    "print(all_extrinsics.shape, all_intrinsics.shape, all_world_points.shape, depth_maps.shape, depth_conf_maps.shape, all_images.shape, aggregated_tokens_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9663664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b42f5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def mask_to_query_points(mask, max_points=100):\n",
    "    \"\"\"\n",
    "    Convert a binary mask to a list of query points (N, 2)\n",
    "    \"\"\"\n",
    "    mask = mask.astype(np.uint8)\n",
    "    coords = np.column_stack(np.where(mask > 0))  # shape: (N, 2) as (row, col)\n",
    "    if coords.shape[0] == 0:\n",
    "        raise ValueError(\"No foreground pixels found in mask.\")\n",
    "    \n",
    "    # Subsample if too many points\n",
    "    if coords.shape[0] > max_points:\n",
    "        idx = np.random.choice(len(coords), max_points, replace=False)\n",
    "        coords = coords[idx]\n",
    "\n",
    "    # Flip from (row, col) to (x, y)\n",
    "    query_points = torch.FloatTensor(coords[:, [1, 0]])  # (N, 2)\n",
    "    return query_points\n",
    "\n",
    "#track_list: torch.Size([4, 1, 8, 50, 2])\n",
    "def visualize_tracks(all_images, track_list, ps_idx_list, radius=2):\n",
    "    \"\"\"\n",
    "    Visualize tracked points on image sequence.\n",
    "    \n",
    "    all_images: (T, 3, H, W) NumPy array\n",
    "    track_list: (T, 1, N, 2) torch.Tensor\n",
    "    ps_idx_list: (N, 2) torch.Tensor or NumPy array\n",
    "    \"\"\"\n",
    "    T = all_images.shape[0]\n",
    "    N = ps_idx_list.shape[0]\n",
    "\n",
    "    # Normalize images if necessary\n",
    "    if all_images.max() <= 1.0:\n",
    "        all_images = (all_images * 255).astype(np.uint8)\n",
    "    else:\n",
    "        all_images = all_images.astype(np.uint8)\n",
    "\n",
    "    # Generate unique colors\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, N))[:, :3] * 255\n",
    "\n",
    "    for t in range(T):\n",
    "        # Convert image to (H, W, 3) and transpose channels\n",
    "        img = np.transpose(all_images[t], (1, 2, 0)).copy()  # (H, W, 3)\n",
    "\n",
    "        for i in range(N):\n",
    "            point = track_list[1, 0, t, i].detach().cpu().numpy()\n",
    "            if np.any(np.isnan(point)) or np.any(np.isinf(point)):\n",
    "                continue\n",
    "            # x, y = int(round(point[0])), int(round(point[1]))\n",
    "            x, y = int(round(float(point[0]))), int(round(float(point[1])))\n",
    "            color = tuple(map(int, colors[i]))\n",
    "            cv2.circle(img, (x, y), radius, color, -1)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Frame {t}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b71db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skhalid/Documents/vggt/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/skhalid/Documents/vggt/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "OBJECT_MASKING\n",
    "'''\n",
    "import torch\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load OWL-ViT\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-large-patch14\").to(device)\n",
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-large-patch14\")\n",
    "\n",
    "# Load SAM\n",
    "sam_checkpoint = \"/home/skhalid/Downloads/sam_vit_l.pth\"\n",
    "sam = sam_model_registry[\"vit_l\"](checkpoint=sam_checkpoint).to(device).eval()\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10cf91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle: 0.71 at box [123  70 399 246]\n",
      "query_points.shape: torch.Size([2500, 2])\n",
      "all_images.shape: (8, 3, 350, 518)\n",
      "ps_idx_list: [5]\n",
      "aggregated_tokens_tensor: torch.Size([24, 1, 8, 930, 2048])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.1259,  0.1244, -0.2035,  ..., -0.0134,  0.0438,  0.2083],\n",
      "          [ 0.3009,  0.1051, -0.2932,  ..., -0.0378, -0.0317,  0.1899],\n",
      "          [ 0.2893,  0.1372, -0.2837,  ..., -0.0229, -0.0321,  0.1597],\n",
      "          ...,\n",
      "          [ 0.1599,  0.0303,  0.0073,  ...,  0.0337,  0.0842,  0.0848],\n",
      "          [ 0.2834,  0.2385, -0.0604,  ...,  0.0200,  0.0172,  0.1497],\n",
      "          [ 0.1142,  0.0102, -0.0569,  ...,  0.0737,  0.0645,  0.1010]],\n",
      "\n",
      "         [[ 0.0818,  0.1083, -0.0269,  ...,  0.1343,  0.0527,  0.0195],\n",
      "          [ 0.0761,  0.0978, -0.0468,  ...,  0.1558,  0.0557,  0.0360],\n",
      "          [ 0.0828,  0.0317, -0.0435,  ...,  0.0844, -0.0303,  0.0932],\n",
      "          ...,\n",
      "          [ 0.0958, -0.0318, -0.0786,  ...,  0.1201, -0.0674,  0.0840],\n",
      "          [-0.0763,  0.1382,  0.0206,  ...,  0.2143,  0.1689,  0.0726],\n",
      "          [ 0.0262, -0.0609, -0.1491,  ...,  0.1326,  0.0061,  0.1204]],\n",
      "\n",
      "         [[ 0.2076,  0.0749, -0.1057,  ..., -0.0732,  0.0327,  0.1807],\n",
      "          [ 0.3364, -0.0596, -0.1243,  ..., -0.0531,  0.0387,  0.1011],\n",
      "          [ 0.2770,  0.1218,  0.0712,  ..., -0.0390,  0.0125,  0.1125],\n",
      "          ...,\n",
      "          [ 0.2319, -0.1149, -0.0144,  ..., -0.0088, -0.0334,  0.0495],\n",
      "          [ 0.1255,  0.0297,  0.0083,  ...,  0.0063,  0.0478,  0.1209],\n",
      "          [ 0.0945,  0.0625, -0.0750,  ...,  0.0100,  0.0709,  0.0800]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1450,  0.0970, -0.1135,  ...,  0.0279,  0.0338,  0.1403],\n",
      "          [ 0.1620,  0.0315, -0.1629,  ...,  0.0741,  0.0169,  0.0649],\n",
      "          [ 0.2571, -0.1139,  0.0918,  ...,  0.0427,  0.0140,  0.0592],\n",
      "          ...,\n",
      "          [ 0.1663,  0.1331,  0.1164,  ...,  0.0446,  0.0016,  0.2689],\n",
      "          [ 0.1032,  0.1948, -0.0228,  ...,  0.1142, -0.0149,  0.2082],\n",
      "          [ 0.1236,  0.1456, -0.0925,  ...,  0.1066, -0.0503,  0.1899]],\n",
      "\n",
      "         [[ 0.2550, -0.1263, -0.1518,  ...,  0.1246,  0.0031,  0.0264],\n",
      "          [ 0.0968,  0.1113, -0.2355,  ...,  0.1137,  0.0074,  0.1025],\n",
      "          [ 0.1536, -0.0606, -0.1690,  ...,  0.0725,  0.0723,  0.1440],\n",
      "          ...,\n",
      "          [ 0.2233, -0.0182, -0.1568,  ...,  0.0719,  0.0537,  0.0240],\n",
      "          [ 0.2639, -0.0920, -0.1157,  ...,  0.0761, -0.0632, -0.0667],\n",
      "          [ 0.2232,  0.0087, -0.1327,  ...,  0.1241,  0.0646,  0.0340]],\n",
      "\n",
      "         [[ 0.1932,  0.0391, -0.0936,  ..., -0.0320,  0.0789,  0.0782],\n",
      "          [ 0.2499,  0.1410, -0.0555,  ...,  0.0211,  0.0140,  0.0993],\n",
      "          [ 0.1622,  0.1738, -0.0462,  ...,  0.0468, -0.0236,  0.1744],\n",
      "          ...,\n",
      "          [ 0.3147,  0.1327, -0.0672,  ..., -0.0572,  0.0145,  0.0536],\n",
      "          [ 0.2332,  0.1650, -0.1004,  ..., -0.0214,  0.0635,  0.0978],\n",
      "          [ 0.1710,  0.1872, -0.0977,  ...,  0.0375,  0.0471,  0.1037]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.0878,  0.3312, -0.2650,  ..., -0.1087, -0.1744,  0.3490],\n",
      "          [-0.0919,  0.2548, -0.4054,  ..., -0.0286, -0.0843,  0.3461],\n",
      "          [-0.1330,  0.3275, -0.3135,  ...,  0.1337, -0.0743,  0.2687],\n",
      "          ...,\n",
      "          [-0.0015,  0.2584,  0.0418,  ..., -0.0725, -0.0303,  0.1528],\n",
      "          [ 0.1531,  0.5510,  0.0249,  ..., -0.0077, -0.1025,  0.1117],\n",
      "          [ 0.0277,  0.2068, -0.0364,  ..., -0.1050, -0.2995,  0.1406]],\n",
      "\n",
      "         [[ 0.1051,  0.2430, -0.0926,  ..., -0.1076, -0.1767,  0.2388],\n",
      "          [ 0.0607,  0.2085, -0.1344,  ..., -0.0591, -0.1002,  0.2945],\n",
      "          [ 0.0189,  0.1102, -0.1465,  ..., -0.1299, -0.2520,  0.3511],\n",
      "          ...,\n",
      "          [ 0.0049,  0.1345, -0.1008,  ...,  0.1276,  0.0807,  0.0099],\n",
      "          [-0.0586,  0.3125,  0.0596,  ...,  0.0311,  0.1227, -0.1290],\n",
      "          [-0.0068,  0.1767, -0.1635,  ...,  0.0560,  0.0816, -0.0361]],\n",
      "\n",
      "         [[ 0.1285,  0.2902, -0.2148,  ..., -0.1607, -0.1963,  0.3779],\n",
      "          [ 0.1067,  0.1775, -0.1622,  ..., -0.2355, -0.0716,  0.2989],\n",
      "          [-0.0143,  0.2545, -0.0216,  ..., -0.0793,  0.0523,  0.3806],\n",
      "          ...,\n",
      "          [ 0.1304,  0.0811, -0.1263,  ...,  0.0952, -0.2146,  0.0240],\n",
      "          [ 0.0576,  0.2109, -0.0577,  ..., -0.0439, -0.1679,  0.1089],\n",
      "          [ 0.0326,  0.2778, -0.0988,  ..., -0.1138, -0.1959,  0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1392,  0.1526, -0.1209,  ..., -0.1810, -0.2989,  0.3732],\n",
      "          [ 0.1056,  0.1862,  0.0260,  ..., -0.0427, -0.0709,  0.2445],\n",
      "          [-0.0516, -0.0040,  0.2156,  ...,  0.0447, -0.0911,  0.1404],\n",
      "          ...,\n",
      "          [ 0.2279,  0.3432,  0.0177,  ..., -0.0229, -0.1340,  0.2369],\n",
      "          [ 0.0413,  0.3938,  0.0443,  ...,  0.0084, -0.2503,  0.1736],\n",
      "          [ 0.0700,  0.3162, -0.0086,  ..., -0.0356, -0.3413,  0.0982]],\n",
      "\n",
      "         [[ 0.2162,  0.1556, -0.1287,  ..., -0.0910, -0.1405,  0.2622],\n",
      "          [ 0.1364,  0.3450, -0.2537,  ..., -0.2769, -0.1720,  0.1748],\n",
      "          [-0.1335,  0.2207, -0.0786,  ..., -0.0096, -0.0086,  0.1030],\n",
      "          ...,\n",
      "          [ 0.0709,  0.2678, -0.1341,  ...,  0.1312, -0.0802, -0.0197],\n",
      "          [ 0.1789,  0.2333, -0.0293,  ...,  0.1199, -0.1258, -0.0251],\n",
      "          [ 0.2813,  0.2316, -0.0966,  ..., -0.0011, -0.1379,  0.1974]],\n",
      "\n",
      "         [[ 0.1252,  0.1957, -0.0307,  ..., -0.1480, -0.0046,  0.0955],\n",
      "          [ 0.1696,  0.3108,  0.1178,  ..., -0.0008,  0.0090,  0.0096],\n",
      "          [ 0.0313,  0.3355,  0.0737,  ..., -0.0329, -0.0981,  0.1659],\n",
      "          ...,\n",
      "          [ 0.2073,  0.3531, -0.1202,  ...,  0.0024, -0.1371,  0.1521],\n",
      "          [ 0.0322,  0.3469, -0.1287,  ..., -0.1899, -0.2337,  0.1656],\n",
      "          [-0.0525,  0.3704, -0.0961,  ..., -0.1930, -0.2818,  0.1392]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[-6.3426e-02,  8.4360e-01,  1.1845e-01,  ..., -4.5075e-01,\n",
      "           -8.4719e-01,  7.8349e-03],\n",
      "          [ 1.1558e-01,  2.2285e+00,  1.5191e+00,  ...,  2.4789e-01,\n",
      "            6.5450e-02,  1.5790e-01],\n",
      "          [-2.2372e-02,  2.3674e+00,  1.7386e+00,  ...,  6.1587e-01,\n",
      "            1.7495e-01, -6.0604e-02],\n",
      "          ...,\n",
      "          [-3.2134e-01, -2.2818e+00, -1.6190e+00,  ..., -2.3106e-01,\n",
      "           -9.7322e-02,  1.0244e-01],\n",
      "          [-3.5353e-01, -2.5650e+00, -1.8983e+00,  ...,  8.1255e-03,\n",
      "           -4.9795e-01, -2.1701e-01],\n",
      "          [-1.6986e-01, -2.2721e+00, -1.8264e+00,  ..., -2.2947e-01,\n",
      "           -2.1704e-01,  8.9574e-04]],\n",
      "\n",
      "         [[ 1.4850e-01, -4.4606e-01, -1.0414e-01,  ..., -1.1914e+00,\n",
      "            1.0921e-01,  4.4544e-01],\n",
      "          [ 2.0058e-01, -3.9881e-01, -2.6987e-01,  ..., -9.1076e-01,\n",
      "           -7.0411e-02,  4.6090e-01],\n",
      "          [ 4.1798e-01, -5.1348e-01, -3.3801e-01,  ..., -8.8622e-01,\n",
      "           -2.4506e-01,  6.2107e-01],\n",
      "          ...,\n",
      "          [ 6.3552e-01,  7.2082e-02,  6.9524e-01,  ...,  2.9504e-01,\n",
      "            4.2038e-01,  3.2659e-01],\n",
      "          [-4.5095e-01,  2.3878e-01,  2.5774e-01,  ..., -1.5764e+00,\n",
      "           -5.5915e-01,  5.0730e-01],\n",
      "          [ 1.5453e-01,  4.2570e-01,  8.2350e-01,  ..., -2.6012e-01,\n",
      "           -4.6742e-02, -3.1898e-01]],\n",
      "\n",
      "         [[-2.1398e-01,  1.3455e+00,  4.4880e-01,  ..., -4.9099e-01,\n",
      "           -1.2352e+00,  1.7777e-01],\n",
      "          [-2.1712e-01,  2.8042e+00,  2.2143e+00,  ...,  1.9057e-01,\n",
      "           -8.4446e-02, -2.8494e-01],\n",
      "          [-2.2612e-01,  2.5240e+00,  2.1335e+00,  ...,  1.5292e-01,\n",
      "           -8.0562e-01, -2.3582e-02],\n",
      "          ...,\n",
      "          [-3.9165e-01, -3.4163e+00, -2.0014e+00,  ...,  3.1497e-01,\n",
      "            1.4631e-01,  2.5350e-01],\n",
      "          [-3.9984e-01, -2.4066e+00, -1.4841e+00,  ...,  3.0232e-01,\n",
      "           -2.2027e-01,  9.8912e-02],\n",
      "          [-3.3492e-01, -2.2657e+00, -1.5839e+00,  ...,  2.2141e-01,\n",
      "           -1.3260e-01, -1.3537e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3578e-01, -3.6175e-01, -1.1382e+00,  ..., -4.3260e-01,\n",
      "           -2.7836e-01, -1.3788e+00],\n",
      "          [-3.2437e-02, -9.0201e-01, -3.7615e-01,  ...,  2.7038e-01,\n",
      "            2.0226e-01, -1.5657e+00],\n",
      "          [-1.5897e-01, -8.3690e-01, -4.3084e-02,  ...,  1.8092e-01,\n",
      "           -3.2960e-01, -1.7707e+00],\n",
      "          ...,\n",
      "          [-4.0106e-01,  1.3458e-01,  3.0495e-01,  ..., -1.3673e-01,\n",
      "           -1.8887e-02,  4.9719e-01],\n",
      "          [-4.8726e-01,  5.6146e-01,  4.4952e-01,  ..., -5.2550e-01,\n",
      "            4.9477e-02,  5.8740e-01],\n",
      "          [-3.5562e-01,  3.4837e-01,  2.4703e-01,  ..., -3.7561e-01,\n",
      "            5.6402e-02,  3.4470e-01]],\n",
      "\n",
      "         [[ 5.5898e-01,  1.7398e+00,  1.1800e+00,  ..., -2.1051e-01,\n",
      "            1.1297e-01, -7.5216e-02],\n",
      "          [ 2.0482e-01,  1.1672e+00,  3.4564e-01,  ..., -9.7540e-01,\n",
      "           -5.5565e-01,  5.0574e-02],\n",
      "          [ 5.6860e-01,  1.2874e+00,  7.6318e-01,  ..., -5.3865e-01,\n",
      "            8.0295e-01, -6.3849e-01],\n",
      "          ...,\n",
      "          [ 3.2742e-01, -8.6914e-01, -1.2526e+00,  ...,  4.3121e-01,\n",
      "           -5.2109e-02,  1.7202e-01],\n",
      "          [ 3.5487e-01, -9.2938e-01, -1.1538e+00,  ...,  8.6431e-01,\n",
      "           -2.8313e-01,  1.6582e-01],\n",
      "          [-4.0415e-02, -6.1132e-01, -7.1040e-01,  ..., -2.2949e-01,\n",
      "           -8.9512e-01,  1.2898e+00]],\n",
      "\n",
      "         [[-1.0039e-01,  8.4833e-01,  1.1326e+00,  ..., -6.9183e-01,\n",
      "           -3.3186e-01, -5.8579e-01],\n",
      "          [ 2.8341e-01,  9.4996e-01,  1.9369e+00,  ..., -2.8273e-01,\n",
      "           -5.9238e-01, -3.4072e-01],\n",
      "          [-4.6759e-02,  1.0151e+00,  1.6934e+00,  ..., -4.7245e-01,\n",
      "           -3.9428e-01, -3.4652e-01],\n",
      "          ...,\n",
      "          [-4.5663e-02, -7.2694e-01, -8.2001e-01,  ...,  3.3429e-02,\n",
      "           -1.3399e-01,  4.1352e-01],\n",
      "          [-1.8884e-01, -4.7476e-01, -7.2483e-01,  ..., -2.1267e-01,\n",
      "           -2.9781e-01,  3.6740e-01],\n",
      "          [-2.4155e-01, -3.3377e-01, -7.0971e-01,  ..., -1.8607e-01,\n",
      "           -1.5841e-01,  4.6638e-01]]]])\n",
      "5 None None\n",
      "torch.Size([1, 8, 925, 2048])\n",
      "tensor([[[[ 0.5232,  1.8714,  0.6139,  ..., -0.9429, -0.4894, -1.8274],\n",
      "          [ 0.5065,  3.2477,  1.8844,  ..., -0.2371,  0.7376, -1.2827],\n",
      "          [ 0.2628,  3.2643,  2.0421,  ...,  0.0189,  0.7003, -1.5214],\n",
      "          ...,\n",
      "          [ 0.9873, -1.2106, -1.1618,  ..., -1.1084, -0.4767, -1.4066],\n",
      "          [ 1.0382, -1.3374, -1.3391,  ..., -0.7572, -0.7344, -1.6366],\n",
      "          [ 0.9739, -1.1850, -1.3168,  ..., -1.3519, -0.6849, -1.4300]],\n",
      "\n",
      "         [[ 0.1162,  0.5203, -0.3753,  ..., -0.8258, -0.3319, -0.9591],\n",
      "          [ 0.2498,  0.8097, -0.3927,  ..., -0.8184, -0.2067, -0.5229],\n",
      "          [ 0.7625,  0.8739, -0.3081,  ..., -0.8279, -0.0208, -0.0623],\n",
      "          ...,\n",
      "          [-0.7101,  0.6277,  0.6378,  ...,  3.0174, -0.5870, -1.7756],\n",
      "          [-1.5860,  1.2154,  0.5232,  ..., -1.5507, -1.5650, -0.5703],\n",
      "          [-0.9921,  0.8778,  0.5800,  ...,  1.7725, -1.1596, -2.1043]],\n",
      "\n",
      "         [[ 0.1596,  2.6547,  1.2224,  ..., -0.9643, -0.9944, -2.2089],\n",
      "          [ 0.2731,  4.0870,  2.9734,  ..., -0.3678,  0.3037, -2.1805],\n",
      "          [ 0.3998,  3.8678,  2.8707,  ..., -0.7738, -0.3230, -1.8470],\n",
      "          ...,\n",
      "          [ 0.8027, -2.2164, -1.2151,  ..., -0.1487,  0.3572, -1.5569],\n",
      "          [ 0.8564, -1.3605, -0.8704,  ..., -0.1011, -0.1107, -1.8934],\n",
      "          [ 0.9415, -1.2276, -0.9654,  ..., -0.2569, -0.0766, -2.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1380,  0.5446, -2.3084,  ...,  1.0443,  1.4545, -1.4422],\n",
      "          [ 1.7617,  0.2774, -2.0629,  ...,  2.4393,  1.4417, -1.3818],\n",
      "          [ 0.9333,  0.0633, -1.7679,  ...,  1.8153,  0.9755, -1.7045],\n",
      "          ...,\n",
      "          [-0.1882,  1.2956,  1.4099,  ..., -1.5766,  0.3552, -1.2453],\n",
      "          [ 0.2381,  1.6820,  1.3678,  ..., -1.9405,  0.4275, -0.8345],\n",
      "          [ 0.1695,  1.4916,  1.1326,  ..., -1.7996,  0.3520, -1.0046]],\n",
      "\n",
      "         [[ 1.8072,  2.6519,  1.6035,  ..., -1.3032,  0.2511, -1.2411],\n",
      "          [ 1.2261,  2.2579,  1.0852,  ..., -1.9754,  0.0372, -1.6677],\n",
      "          [ 2.0124,  2.2015,  1.3193,  ..., -2.1504,  1.2138, -2.0270],\n",
      "          ...,\n",
      "          [ 0.8061, -0.0548, -1.0241,  ..., -0.6240,  0.0978, -0.6364],\n",
      "          [ 1.0507, -0.1367, -1.0012,  ..., -0.2262, -0.1926, -0.6764],\n",
      "          [ 0.2597,  0.1243, -0.8417,  ..., -0.2500, -0.1504, -0.1217]],\n",
      "\n",
      "         [[ 0.4419,  1.9253,  1.2544,  ...,  1.0133,  0.6522, -1.5997],\n",
      "          [ 0.4475,  1.8666,  1.9161,  ...,  0.9820,  0.5765, -1.4563],\n",
      "          [ 0.1171,  2.3347,  1.9583,  ...,  0.6564,  0.9339, -1.5113],\n",
      "          ...,\n",
      "          [ 1.1442,  0.4232, -0.0798,  ..., -0.5633,  0.1070, -1.1975],\n",
      "          [ 1.1158,  0.6253, -0.0551,  ..., -0.9206, -0.2869, -1.2353],\n",
      "          [ 1.2383,  0.7389, -0.0756,  ..., -0.8615, -0.2700, -1.0975]]]])\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "SCORE_THRESHOLD = 0.5\n",
    "# image_paths = [\"/home/skhalid/Documents/data/tandt_db/tandt/truck/images/000001.jpg\"]\n",
    "# # image_paths = [\"/home/skhalid/Documents/data/nerf_synthetic/lego/images/r_0.png\"]\n",
    "# # image_paths = [\"/home/skhalid/Documents/data/bicycle/images_4/_DSC8679.JPG\"]\n",
    "# # image_paths = [\"/home/skhalid/Documents/data/Synthetic4Relight/hotdog/train/000.png\"]\n",
    "# # image_paths = [\"/home/skhalid/Documents/data/data_dtu/DTU_scan24/inputs/images/000000.png\"]\n",
    "# # image_paths = [\"/home/skhalid/Documents/data/banana/images/frame_00002.JPG\"]\n",
    "# image_paths = []\n",
    "\n",
    "object_masks = []\n",
    "\n",
    "for image_path in image_names:\n",
    "    image = Image.open(image_path).convert(\"RGB\").resize((518, 350), resample=Image.BILINEAR) # <--- match VGGT\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Text prompt\n",
    "    # texts = [[\"car\", \"bicycle\", \"trees\", \"grass\", \"ground\", \"bench\", \"lego\", \"fruit\"]]  # You can modify this list\n",
    "    texts = [[\"truck\", \"bicycle\", \"ground\", \"bench\", \"tree\", \"chair\", \"building\", \"sky\", \"clouds\", \"road\", \"lego\", \"grass\", \"toy\", \"hotdog\", \"fruit\", \"food\", \"window\"]]\n",
    "\n",
    "    # Prepare input for OWL-ViT\n",
    "    inputs = processor(text=texts, images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Detect with OWL-ViT\n",
    "    # print(\"Begin detect\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # print(\"End detect\")\n",
    "\n",
    "    # Get boxes and scores\n",
    "    target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=SCORE_THRESHOLD)[0]\n",
    "\n",
    "    # Run SAM\n",
    "    predictor.set_image(image_np)\n",
    "\n",
    "    # Process each box from OWL-ViT\n",
    "    for i, (box, score, label) in enumerate(zip(results[\"boxes\"], results[\"scores\"], results[\"labels\"])):\n",
    "\n",
    "        # Modify the class as needed\n",
    "        if texts[0][label] == \"bicycle\":\n",
    "            box = box.cpu().numpy().astype(int)\n",
    "            x0, y0, x1, y1 = box\n",
    "            print(f\"{texts[0][label]}: {score:.2f} at box {box}\")\n",
    "\n",
    "            # SAM expects box in XYXY format\n",
    "            input_box = np.array([x0, y0, x1, y1])\n",
    "            masks, _, _ = predictor.predict(box=input_box[None, :], multimask_output=False)\n",
    "\n",
    "            # Overlay mask\n",
    "            mask = masks[0]\n",
    "            overlay = image_np.copy()\n",
    "            overlay[mask] = (255, 0, 0)  # Red mask\n",
    "\n",
    "            # Convert mask to query points\n",
    "            query_points = mask_to_query_points(mask, max_points=1000).to(device_vggt)\n",
    "\n",
    "            # Track\n",
    "            print(\"query_points.shape: {}\".format(query_points.shape))\n",
    "            print(\"all_images.shape: {}\".format(all_images.shape))\n",
    "            print(\"ps_idx_list: {}\".format(ps_idx_list))\n",
    "            print(\"aggregated_tokens_tensor: {}\".format(aggregated_tokens_tensor.shape))\n",
    "            track_list, vis_score, conf_score = model_vggt.track_head(\n",
    "                aggregated_tokens_tensor, \n",
    "                all_images[None], \n",
    "                ps_idx_list[0], \n",
    "                query_points=query_points[None]\n",
    "            )\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(overlay, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "            cv2.putText(overlay, f\"{texts[0][label]} {score:.2f}\", (x0, y0 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            # Show\n",
    "            plt.imshow(overlay)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            resized_mask = cv2.resize(mask.astype(np.uint8), (depth_conf_maps[0].shape[1], depth_conf_maps[0].shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            resized_mask = resized_mask[None, ...].astype(np.float32)\n",
    "            \n",
    "            # Visualize\n",
    "            track_list = torch.stack(track_list)\n",
    "            query_points = query_points.detach().cpu().numpy()\n",
    "            visualize_tracks(all_images, track_list, query_points)\n",
    "\n",
    "            # break\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    object_masks.append(resized_mask)\n",
    "\n",
    "object_masks = np.concatenate((object_masks), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mask.view(depth_conf_maps[0].shape[0], depth_conf_maps[0].shape[1]).shape, depth_conf_maps[0].shape)\n",
    "print(mask.shape, resized_mask.shape, depth_conf_maps[0].shape, object_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = all_intrinsics.shape[0]\n",
    "MASKING_MODE = \"object\"\n",
    "\n",
    "for i in range(N):\n",
    "    # filter out pixels\n",
    "    if MASKING_MODE == \"depth\":\n",
    "        conf_mask = depth_conf_maps[i]\n",
    "    elif MASKING_MODE == \"object\":\n",
    "        conf_mask = object_masks[i]\n",
    "    else:\n",
    "        assert MASKING_MODE == \"depth\" or MASKING_MODE == \"object\"\n",
    "\n",
    "    conf_mask /= conf_mask.max()\n",
    "    conf_mask[conf_mask<0.5] = 0.0\n",
    "    conf_mask[conf_mask>0.0] = 1.0\n",
    "    all_world_points[i, :] *= conf_mask[..., None]\n",
    "    depth_maps[i, :] *= conf_mask[..., None]\n",
    "    all_images[i, :] *= conf_mask[None, ...].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9eed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da43e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
